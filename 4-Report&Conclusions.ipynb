{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyML9mpr8FKJev8nlLwp1Q0T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Chosen Model: SVM with TF-IDF.\n","\n","After trying several models and vectorization techniques, I have chosen the Support Vector Machine (SVM) with the best parameters obtained through hyperparameter search.\n","\n","**Metrics obtained:**\n","1. Accuracy:\n"," * Value: 0.85.\n"," * The model correctly predicted 85% of the instances, this indicates a good overall performance.\n","2. Precision:\n"," * Class 0: 0.84\n"," * Class 1: 0.86\n"," * Precision is important when trying to avoid false positives. The model has similar precision for both classes which suggests it is quite reliable when predicting a sample belonging, especially for class 1.\n","3. Recall:\n"," * Class 0: 0.86\n"," * Class 1: 0.84\n"," * Recall reflects the model's ability when correctly identifying all instances of each class. It performs slightly better when identifying class 0 than clas 1 which may indicate a slight bias toward class 0.\n","4. F1-Score:\n"," * Class 0: 0.85\n"," * Class 1: 0.85\n"," * F1-Score is a combined measure of precision and recall. We have a well.balanced result. Both classes have 0.85 which is a sign of a balanced performance.\n","\n","**Additional metrics:**\n","1. AUC-ROC:\n","  * 0.90\n","  * Indicates the model has a good ability to distinguish between the two classes.\n","2. Confusion matrix:\n","  * [[42, 7], [8, 43]]\n","  * Out of 49 instances of class 0, the model correctly predicted 42 and made 7 false positives. Out of 51 instances of class 1, the model correctly predicted 43 and made 8 false negatives.\n","3. Cross-validation:\n","  * 0.82 Â± 0.02, which indicates that the model is relatively consistent, with low variability across different data partitions.\n","\n","**Comments:**\n","* The precision and recall metrics are quite balanced between the two classes, suggesting that the model is handling the problem well without being biased toward any class.\n","* Although I tried several models, SVM with IF-IFD vectorization turned out to be the best-performing one in terms of precision, recall and F1-score.\n","* With the hyperparameter search, I was able to find the best parameters for the model: `C=1`, `gamma='scale'`, and `kernel=rbf'`, although they did not make any significant change or improvement on the model.\n","\n","\n","## Conclusions:\n","The chosen SVM model achieved an accuracy of 85%, what is a promising result for a baniry classification problem which has been trained with less than 500 samples. Furthermore, the precision, recall and F1-score metrics are also well-balanced.\n","\n","The additional metrics confirm that the model has strong discriminative power between the classes, with controled false positives and false negatives.\n","\n","Considering both the accuracy and additional metrics, we can conclude that the SVM model is a good choice for this type of problem. The results are strong, and the model shows consistent performance across different validation methods.\n","\n","If further improvements is desired, option such as fine-tuning additional parameters or experimenting with more advanced preprocessing techniques, like more complex tokenization or using word embeddings, could be considered. Also, the use of pretrained models like BERT, FastText or Naive Bayes may be a good option.\n"],"metadata":{"id":"1ZF2mw9zG8F-"}}]}